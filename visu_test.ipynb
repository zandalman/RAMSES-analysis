{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd9610cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import math\n",
    "import os\n",
    "from scipy.io import FortranFile\n",
    "from types import SimpleNamespace\n",
    "from astropy.io import ascii\n",
    "from config import *\n",
    "import const\n",
    "\n",
    "from functions import move_to_sim_dir, get_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "29a77431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving to directory '/home/za9132/scratch/romain/round9/fiducial'.\n"
     ]
    }
   ],
   "source": [
    "sim_round = 9\n",
    "sim_name = 'fiducial'\n",
    "dump = 54\n",
    "\n",
    "move_to_sim_dir(sim_round, sim_name)\n",
    "info = get_info(dump)\n",
    "os.chdir(\"output_{dump:05d}\".format(dump=dump))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dece1ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"{filetype}_{dump:05d}.txt\"\n",
    "\n",
    "with open(filename.format(filetype='info', dump=dump)) as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "info = SimpleNamespace()\n",
    "for line in content:\n",
    "    line_sp = line.split(\"=\")\n",
    "    if len(line_sp) > 1:\n",
    "        try:\n",
    "            setattr(info, line_sp[0].strip(), eval(line_sp[1].strip()))\n",
    "        except NameError:\n",
    "            setattr(info, line_sp[0].strip(), line_sp[1].strip())\n",
    "            \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a777d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the number of variables from the hydro_file_descriptor.txt\n",
    "hydrofile = infile+\"/hydro_file_descriptor.txt\"\n",
    "list_vars, _ = read_descriptor(hydrofile)\n",
    "\n",
    "# Store the total number of hydro variables\n",
    "info[\"nvar\"] = len(list_vars)\n",
    "\n",
    "# Make sure we always read the coordinates\n",
    "list_vars.extend((\"level\",\"x\",\"y\",\"z\",\"dx\"))\n",
    "nvar_read = len(list_vars)\n",
    "\n",
    "# Now read the amr and hydro files =============================================\n",
    "# We have to open the files in binary format, and count all the bytes in the ===\n",
    "# file structure to extract just the data we need. =============================\n",
    "# See output_amr.f90 and output_hydro.f90 in the RAMSES source. ================\n",
    "print(\"Processing %i files in \" % (info[\"ncpu\"]) + infile)\n",
    "\n",
    "# We will store the cells in a dictionary which we build as we go along.\n",
    "# The final concatenation into a single array will be done once at the end.\n",
    "data_pieces = dict()\n",
    "npieces = 0\n",
    "\n",
    "# Allocate work arrays\n",
    "twotondim = 2**info[\"ndim\"]\n",
    "xcent = np.zeros([8,3],dtype=np.float64)\n",
    "xg    = np.zeros([info[\"ngridmax\"],3],dtype=np.float64)\n",
    "son   = np.zeros([info[\"ngridmax\"],twotondim],dtype=np.int32)\n",
    "var   = np.zeros([info[\"ngridmax\"],twotondim,nvar_read],dtype=np.float64)\n",
    "xyz   = np.zeros([info[\"ngridmax\"],twotondim,info[\"ndim\"]],dtype=np.float64)\n",
    "ref   = np.zeros([info[\"ngridmax\"],twotondim],dtype=bool) # np.bool removed for numpy>=1.24\n",
    "\n",
    "partinfofile = infile+\"/header_\"+infile.split(\"_\")[-1]+\".txt\"\n",
    "info[\"particle_count\"] = {}\n",
    "try:\n",
    "    _lines = open(partinfofile).readlines()[1:-2]\n",
    "    Nparttot = 0\n",
    "    for line in _lines:\n",
    "        part_type, _tmp = line.split()\n",
    "        part_count = int(_tmp)\n",
    "        info[\"particle_count\"][part_type] = part_count\n",
    "        Nparttot += part_count\n",
    "    info[\"particle_count\"][\"total\"] = Nparttot\n",
    "\n",
    "    particle_vars, particle_dtypes = read_descriptor(infile + \"/part_file_descriptor.txt\")\n",
    "except FileNotFoundError:\n",
    "    info[\"particle_count\"][\"total\"] = 0\n",
    "    particle_vars, particle_dtypes = []\n",
    "npart_var = len(particle_vars)\n",
    "npart_read = 0\n",
    "\n",
    "part_data = np.zeros([info[\"particle_count\"][\"total\"], npart_var], dtype=np.float64)\n",
    "\n",
    "iprog = 1\n",
    "istep = 10\n",
    "ncells_tot = 0\n",
    "\n",
    "# Loop over the cpus and read the AMR and HYDRO files in binary format\n",
    "for k in range(info[\"ncpu\"]):\n",
    "\n",
    "    # Print progress\n",
    "    percentage = int(float(k)*100.0/float(info[\"ncpu\"]))\n",
    "    if percentage >= iprog*istep:\n",
    "        print(\"%3i%% : read %10i cells\" % (percentage,ncells_tot))\n",
    "        iprog += 1\n",
    "\n",
    "    # Read binary AMR file\n",
    "    amr_fname = generate_fname(nout,ftype=\"amr\",cpuid=k+1)\n",
    "    with open(amr_fname, mode='rb') as amr_file: # b is important -> binary\n",
    "        amrContent = amr_file.read()\n",
    "\n",
    "    # Read binary HYDRO file\n",
    "    hydro_fname = generate_fname(nout,ftype=\"hydro\",cpuid=k+1)\n",
    "    with open(hydro_fname, mode='rb') as hydro_file: # b is important -> binary\n",
    "        hydroContent = hydro_file.read()\n",
    "\n",
    "\n",
    "    # Need to extract info from the file header on the first loop\n",
    "    if k == 0:\n",
    "\n",
    "        # nx,ny,nz\n",
    "        ninteg = 2\n",
    "        nfloat = 0\n",
    "        nlines = 2\n",
    "        nstrin = 0\n",
    "        nquadr = 0\n",
    "        offset = 4*ninteg + 8*(nlines+nfloat) + nstrin + nquadr*16 + 4\n",
    "        [nx,ny,nz] = struct.unpack(\"3i\", amrContent[offset:offset+12])\n",
    "        ncoarse = nx*ny*nz\n",
    "        xbound = [float(int(nx/2)),float(int(ny/2)),float(int(nz/2))]\n",
    "\n",
    "        # nboundary\n",
    "        ninteg = 7\n",
    "        nfloat = 0\n",
    "        nlines = 5\n",
    "        nstrin = 0\n",
    "        nquadr = 0\n",
    "        offset = 4*ninteg + 8*(nlines+nfloat) + nstrin + nquadr*16 + 4\n",
    "        nboundary = struct.unpack(\"i\", amrContent[offset:offset+4])[0]\n",
    "        ngridlevel = np.zeros([info[\"ncpu\"]+nboundary,info[\"levelmax\"]],dtype=np.int32)\n",
    "\n",
    "        # noutput\n",
    "        ninteg = 9\n",
    "        nfloat = 1\n",
    "        nlines = 8\n",
    "        nstrin = 0\n",
    "        nquadr = 0\n",
    "        offset = 4*ninteg + 8*(nlines+nfloat) + nstrin + nquadr*16 + 4\n",
    "        noutput = struct.unpack(\"i\", amrContent[offset:offset+4])[0]\n",
    "\n",
    "        # dtold, dtnew\n",
    "        ninteg = 12\n",
    "        nfloat = 2+2*noutput\n",
    "        nlines = 12\n",
    "        nstrin = 0\n",
    "        nquadr = 0\n",
    "        offset = 4*ninteg + 8*(nlines+nfloat) + nstrin + nquadr*16 + 4\n",
    "        info[\"dtold\"] = struct.unpack(\"%id\"%info[\"levelmax\"], amrContent[offset:offset+8*info[\"levelmax\"]])\n",
    "\n",
    "        # info[\"dtold\"] = eng.get_binary_data(fmt=\"%id\"%(self.info[\"levelmax\"]),\\\n",
    "                             # content=amrContent,ninteg=ninteg,nlines=nlines,nfloat=nfloat)\n",
    "        nfloat += 1 + info[\"levelmax\"]\n",
    "        nlines += 1\n",
    "        offset = 4*ninteg + 8*(nlines+nfloat) + nstrin + nquadr*16 + 4\n",
    "        info[\"dtnew\"] = struct.unpack(\"%id\"%info[\"levelmax\"], amrContent[offset:offset+8*info[\"levelmax\"]])\n",
    "        # info[\"dtnew\"] = eng.get_binary_data(fmt=\"%id\"%(self.info[\"levelmax\"]),\\\n",
    "        #                      content=amrContent,ninteg=ninteg,nlines=nlines,nfloat=nfloat)\n",
    "\n",
    "    # Read the number of grids\n",
    "    ninteg = 14+(2*info[\"ncpu\"]*info[\"levelmax\"])\n",
    "    nfloat = 18+(2*noutput)+(2*info[\"levelmax\"])\n",
    "    nlines = 21\n",
    "    nstrin = 0\n",
    "    nquadr = 0\n",
    "    offset = 4*ninteg + 8*(nlines+nfloat) + nstrin + nquadr*16 + 4\n",
    "    ngridlevel[:info[\"ncpu\"],:] = np.asarray(struct.unpack(\"%ii\"%(info[\"ncpu\"]*info[\"levelmax\"]), amrContent[offset:offset+4*info[\"ncpu\"]*info[\"levelmax\"]])).reshape(info[\"levelmax\"],info[\"ncpu\"]).T\n",
    "\n",
    "    # Read boundary grids if any\n",
    "    if nboundary > 0:\n",
    "        ninteg = 14+(3*info[\"ncpu\"]*info[\"levelmax\"])+(10*info[\"levelmax\"])+(2*nboundary*info[\"levelmax\"])\n",
    "        nfloat = 18+(2*noutput)+(2*info[\"levelmax\"])\n",
    "        nlines = 25\n",
    "        nstrin = 0\n",
    "        nquadr = 0\n",
    "        offset = 4*ninteg + 8*(nlines+nfloat) + nstrin + nquadr*16 + 4\n",
    "        ngridlevel[info[\"ncpu\"]:info[\"ncpu\"]+nboundary,:] = np.asarray(struct.unpack(\"%ii\"%(nboundary*info[\"levelmax\"]), amrContent[offset:offset+4*nboundary*info[\"levelmax\"]])).reshape(info[\"levelmax\"],nboundary).T\n",
    "\n",
    "    # Determine bound key precision\n",
    "    ninteg = 14+(3*info[\"ncpu\"]*info[\"levelmax\"])+(10*info[\"levelmax\"])+(3*nboundary*info[\"levelmax\"])+5\n",
    "    nfloat = 18+(2*noutput)+(2*info[\"levelmax\"])\n",
    "    nlines = 21+2+3*min(1,nboundary)+1+1\n",
    "    nstrin = 128\n",
    "    nquadr = 0\n",
    "    offset = 4*ninteg + 8*(nlines+nfloat) + nstrin + nquadr*16\n",
    "    key_size = struct.unpack(\"i\", amrContent[offset:offset+4])[0]\n",
    "\n",
    "    # Offset for AMR\n",
    "    ninteg1 = 14+(3*info[\"ncpu\"]*info[\"levelmax\"])+(10*info[\"levelmax\"])+(3*nboundary*info[\"levelmax\"])+5+3*ncoarse\n",
    "    nfloat1 = 18+(2*noutput)+(2*info[\"levelmax\"])\n",
    "    nlines1 = 21+2+3*min(1,nboundary)+1+1+1+3\n",
    "    nstrin1 = 128 + key_size\n",
    "\n",
    "    # Offset for HYDRO\n",
    "    ninteg2 = 5\n",
    "    nfloat2 = 1\n",
    "    nlines2 = 6\n",
    "    nstrin2 = 0\n",
    "\n",
    "    # Loop over levels\n",
    "    for ilevel in range(info[\"levelmax\"]):\n",
    "\n",
    "        # Geometry\n",
    "        dxcell=0.5**(ilevel+1)\n",
    "        dx2=0.5*dxcell\n",
    "        for ind in range(twotondim):\n",
    "            iz=int((ind)/4)\n",
    "            iy=int((ind-4*iz)/2)\n",
    "            ix=int((ind-2*iy-4*iz))\n",
    "            xcent[ind,0]=(float(ix)-0.5)*dxcell\n",
    "            xcent[ind,1]=(float(iy)-0.5)*dxcell\n",
    "            xcent[ind,2]=(float(iz)-0.5)*dxcell\n",
    "\n",
    "        # Cumulative offsets in AMR file\n",
    "        ninteg_amr = ninteg1\n",
    "        nfloat_amr = nfloat1\n",
    "        nlines_amr = nlines1\n",
    "        nstrin_amr = nstrin1\n",
    "\n",
    "        # Cumulative offsets in HYDRO file\n",
    "        ninteg_hydro = ninteg2\n",
    "        nfloat_hydro = nfloat2\n",
    "        nlines_hydro = nlines2\n",
    "        nstrin_hydro = nstrin2\n",
    "\n",
    "        # Loop over domains\n",
    "        for j in range(nboundary+info[\"ncpu\"]):\n",
    "\n",
    "            ncache = ngridlevel[j,ilevel]\n",
    "\n",
    "            # Skip two lines of integers\n",
    "            nlines_hydro += 2\n",
    "            ninteg_hydro += 2\n",
    "\n",
    "            if ncache > 0:\n",
    "\n",
    "                if j == k:\n",
    "                    # xg: grid coordinates\n",
    "                    ninteg = ninteg_amr + ncache*3\n",
    "                    nfloat = nfloat_amr\n",
    "                    nlines = nlines_amr + 3\n",
    "                    nstrin = nstrin_amr\n",
    "                    for n in range(info[\"ndim\"]):\n",
    "                        offset = 4*ninteg + 8*(nlines+nfloat+n*(ncache+1)) + nstrin + 4\n",
    "                        xg[:ncache,n] = struct.unpack(\"%id\"%(ncache), amrContent[offset:offset+8*ncache])\n",
    "\n",
    "                    # son indices\n",
    "                    ninteg = ninteg_amr + ncache*(4+2*info[\"ndim\"])\n",
    "                    nfloat = nfloat_amr + ncache*info[\"ndim\"]\n",
    "                    nlines = nlines_amr + 4 + 3*info[\"ndim\"]\n",
    "                    nstrin = nstrin_amr\n",
    "                    for ind in range(twotondim):\n",
    "                        offset = 4*(ninteg+ind*ncache) + 8*(nlines+nfloat+ind) + nstrin + 4\n",
    "                        son[:ncache,ind] = struct.unpack(\"%ii\"%(ncache), amrContent[offset:offset+4*ncache])\n",
    "                        # var: hydro variables\n",
    "                        #jvar = 0\n",
    "                        for ivar in range(info[\"nvar\"]):\n",
    "                            #if var_read[ivar]:\n",
    "                            offset = 4*ninteg_hydro + 8*(nlines_hydro+nfloat_hydro+(ind*info[\"nvar\"]+ivar)*(ncache+1)) + nstrin_hydro + 4\n",
    "                            var[:ncache,ind,ivar] = struct.unpack(\"%id\"%(ncache), hydroContent[offset:offset+8*ncache])\n",
    "                            #jvar += 1\n",
    "                        var[:ncache,ind,-5] = float(ilevel+1)\n",
    "                        for n in range(info[\"ndim\"]):\n",
    "                            xyz[:ncache,ind,n] = xg[:ncache,n] + xcent[ind,n]-xbound[n]\n",
    "                            var[:ncache,ind,-4+n] = xyz[:ncache,ind,n]*info[\"boxlen\"]\n",
    "                        var[:ncache,ind,-1] = dxcell*info[\"boxlen\"]\n",
    "                        # ref: True if the cell is unrefined\n",
    "                        ref[:ncache,ind] = np.logical_not(np.logical_and(son[:ncache,ind] > 0,ilevel < info[\"levelmax\"]-1))\n",
    "\n",
    "                    cube = np.where(ref[:ncache,:])\n",
    "                    cells = var[cube]\n",
    "                    ncells = np.shape(cells)[0]\n",
    "                    if ncells > 0:\n",
    "                        ncells_tot += ncells\n",
    "                        npieces += 1\n",
    "                        # Add the cells in the master dictionary\n",
    "                        data_pieces[\"piece\"+str(npieces)] = cells\n",
    "\n",
    "                # Now increment the offsets while looping through the domains\n",
    "                ninteg_amr += ncache*(4+3*twotondim+2*info[\"ndim\"])\n",
    "                nfloat_amr += ncache*info[\"ndim\"]\n",
    "                nlines_amr += 4 + 3*twotondim + 3*info[\"ndim\"]\n",
    "\n",
    "                nfloat_hydro += ncache*twotondim*info[\"nvar\"]\n",
    "                nlines_hydro += twotondim*info[\"nvar\"]\n",
    "\n",
    "        # Now increment the offsets while looping through the levels\n",
    "        ninteg1 = ninteg_amr\n",
    "        nfloat1 = nfloat_amr\n",
    "        nlines1 = nlines_amr\n",
    "        nstrin1 = nstrin_amr\n",
    "\n",
    "        ninteg2 = ninteg_hydro\n",
    "        nfloat2 = nfloat_hydro\n",
    "        nlines2 = nlines_hydro\n",
    "        nstrin2 = nstrin_hydro\n",
    "\n",
    "    # Read binary particle file\n",
    "    if info[\"particle_count\"][\"total\"] > 0:\n",
    "        part_fname = generate_fname(nout,ftype=\"part\",cpuid=k+1)\n",
    "        with open(part_fname, mode='rb') as part_file:\n",
    "            partContent = part_file.read()\n",
    "        npart, = struct.unpack(\"i\", partContent[28:32])\n",
    "        pcounts = info[\"particle_count\"]\n",
    "        has_tracers = any(v for k, v in pcounts.items() if k.endswith(\"_tracer\"))\n",
    "        # Offset to \"mstar_tot\"\n",
    "        offset = 72\n",
    "        if has_tracers:\n",
    "            offset += struct.calcsize(\"4i\")  # tracer_seed\n",
    "\n",
    "        # Read mstar, mstar_lost\n",
    "        mstar, = struct.unpack(\"d\", partContent[offset+4:offset+12])\n",
    "        offset += 4+8+4  # mstar\n",
    "        mstar_lost, = struct.unpack(\"d\", partContent[offset+4:offset+12])\n",
    "        offset += 4+8+4  # mstar_lost\n",
    "        offset += 4+4+4  # nsink\n",
    "        offset += 4      # jump to beginning of record\n",
    "\n",
    "        for ivar, var_dtype in enumerate(particle_dtypes):\n",
    "            s = struct.calcsize(var_dtype)\n",
    "            endPos = offset + s * npart\n",
    "            part_data[npart_read:npart_read+npart, ivar] = struct.unpack(\"%s%s\" % (npart, var_dtype), partContent[offset:endPos])\n",
    "            offset = endPos + 8\n",
    "\n",
    "        npart_read += npart\n",
    "    else:\n",
    "        mstar = mstar_lost = np.nan\n",
    "\n",
    "# Merge all the data pieces into the master data array\n",
    "master_data_array = np.concatenate(list(data_pieces.values()), axis=0)\n",
    "\n",
    "# Free memory\n",
    "del data_pieces,xcent,xg,son,var,xyz,ref\n",
    "\n",
    "\n",
    "print(\"Total number of cells loaded: %i\" % ncells_tot)\n",
    "if npart_read > 0:\n",
    "    print(\"Total particles loaded: %i\" % npart_read)\n",
    "\n",
    "# This is the master data dictionary.\n",
    "data = {\"data\": {}, \"info\": info, \"sinks\": {\"nsinks\": 0}, \"stellars\": {\"nstellars\": 0}}\n",
    "for i in range(len(list_vars)):\n",
    "    theKey = list_vars[i]\n",
    "    data[\"data\"][theKey] = master_data_array[:,i]\n",
    "\n",
    "if npart_read > 0:\n",
    "    data[\"particle\"] = {}\n",
    "    for ivar, var_name in enumerate(particle_vars):\n",
    "        data[\"particle\"][var_name] = part_data[:, ivar].copy()\n",
    "\n",
    "del part_data\n",
    "\n",
    "data[\"info\"][\"mstar\"] = mstar\n",
    "data[\"info\"][\"mstar_lost\"] = mstar_lost\n",
    "\n",
    "# Append useful variables to dictionary\n",
    "data[\"data\"][\"unit_d\"] = info[\"unit_d\"]\n",
    "data[\"data\"][\"unit_l\"] = info[\"unit_l\"]\n",
    "data[\"data\"][\"unit_t\"] = info[\"unit_t\"]\n",
    "data[\"data\"][\"boxlen\"] = info[\"boxlen\"]\n",
    "data[\"data\"][\"ncells\"] = ncells_tot\n",
    "data[\"data\"][\"time\"  ] = info[\"time\"]\n",
    "\n",
    "# Read sink particles if present\n",
    "sinkfile = infile+\"/sink_\"+infile.split(\"_\")[-1]+\".csv\"\n",
    "try:\n",
    "    with open(sinkfile) as f:\n",
    "        content = f.readlines()\n",
    "    # Read the file header to get information on fields\n",
    "    sink_vars = content[0].rstrip().replace(\" # \", \"\").split(\",\")\n",
    "    sink_units = content[1].rstrip().replace(\" # \", \"\").split(\",\")\n",
    "    data[\"sinks\"][\"nsinks\"] = len(content) - 2\n",
    "    if data[\"sinks\"][\"nsinks\"] > 0:\n",
    "        # sinks = dict()\n",
    "        for entry in sink_vars:\n",
    "            data[\"sinks\"][entry] = np.zeros(data[\"sinks\"][\"nsinks\"], dtype=np.float64)\n",
    "        for i in range(data[\"sinks\"][\"nsinks\"]):\n",
    "            # line = np.asarray(content[i+2].rstrip().split(\",\"), dtype=np.float64)\n",
    "            line = content[i+2].rstrip().split(\",\")\n",
    "            for j, entry in enumerate(sink_vars):\n",
    "                # Try to convert to float\n",
    "                try:\n",
    "                    data[\"sinks\"][entry][i] = np.float64(line[j])\n",
    "                except ValueError:\n",
    "                    data[\"sinks\"][entry][i] = np.nan\n",
    "        data[\"sinks\"][\"id\"] = np.int32(data[\"sinks\"][\"id\"])\n",
    "        data[\"sinks\"][\"level\"] = np.int32(data[\"sinks\"][\"level\"])\n",
    "except IOError:\n",
    "    pass\n",
    "\n",
    "# Read stellar particles if present\n",
    "stellarfile = infile+\"/stellar_\"+infile.split(\"_\")[-1]+\".csv\"\n",
    "try:\n",
    "    with open(stellarfile) as f:\n",
    "        content = f.readlines()\n",
    "    # Read the file header to get information on fields\n",
    "    stellar_vars = content[0].rstrip().replace(\" # \", \"\").split(\",\")\n",
    "    stellar_units = content[1].rstrip().replace(\" # \", \"\").split(\",\")\n",
    "    data[\"stellars\"][\"nstellars\"] = len(content) - 2\n",
    "    if data[\"stellars\"][\"nstellars\"] > 0:\n",
    "        for entry in stellar_vars:\n",
    "            data[\"stellars\"][entry] = np.zeros(data[\"stellars\"][\"nstellars\"], dtype=np.float64)\n",
    "        for i in range(data[\"stellars\"][\"nstellars\"]):\n",
    "            line = content[i+2].rstrip().split(\",\")\n",
    "            for j, entry in enumerate(stellar_vars):\n",
    "                # Try to convert to float\n",
    "                try:\n",
    "                    data[\"stellars\"][entry][i] = np.float64(line[j])\n",
    "                except ValueError:\n",
    "                    data[\"stellars\"][entry][i] = np.nan\n",
    "        data[\"stellars\"][\"id\"] = np.int32(data[\"stellars\"][\"id\"])\n",
    "except IOError:\n",
    "    pass\n",
    "\n",
    "return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40184a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5372812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c03da54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15090c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9d969c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dc7c6ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info2(dump):\n",
    "    \n",
    "    info = SimpleNamespace()\n",
    "    filename = \"output_{dump:05d}/amr_{dump:05d}.out00001\".format(dump=dump)\n",
    "    \n",
    "    with FortranFile(filename, 'r') as f:\n",
    "        \n",
    "        info.ncpu, = f.read_ints('i')\n",
    "        info.ndim, = f.read_ints('i')\n",
    "        nx, ny, nz = f.read_ints('i')\n",
    "        info.nlevelmax, = f.read_ints('i')\n",
    "        \n",
    "        ngridmax, = f.read_ints('i')\n",
    "        nboundary, = f.read_ints('i')\n",
    "        ngrid_current, = f.read_ints('i')\n",
    "        info.boxlen, = f.read_reals('f8')\n",
    "        \n",
    "        noutput, iout, ifout = f.read_ints('i')\n",
    "        tout = f.read_reals('f8')\n",
    "        aout = f.read_reals('f8')\n",
    "        info.t, = f.read_reals('f8')\n",
    "        dtold = f.read_reals('f8')\n",
    "        dtnew = f.read_reals('f8')\n",
    "        nstep,nstep_coarse = f.read_ints('i')\n",
    "        einit, mass_tot_0, rho_tot = f.read_reals('f8')\n",
    "        info.omega_m, info.omega_l, info.omega_k, info.omega_b, info.h0, aexp_ini,boxlen_ini = f.read_reals('f8')\n",
    "        info.aexp, hexp, aexp_old, epot_tot_int, epot_tot_old = f.read_reals('f8')\n",
    "        mass_sph, = f.read_reals('f8')\n",
    "        \n",
    "        headl = f.read_ints('i')\n",
    "        taill = f.read_ints('i')\n",
    "        numbl = f.read_ints('i')\n",
    "        numbl = numbl.reshape(info.nlevelmax, info.ncpu)\n",
    "        numbtot = f.read_ints('i')\n",
    "        \n",
    "        xbound = [0, 0, 0]\n",
    "        if (nboundary > 0):\n",
    "            headb = f.read_ints('i')\n",
    "            tailb = f.read_ints('i')\n",
    "            numbb = f.read_ints('i')\n",
    "            numbb = numbb.reshape(nlevelmax, nboundary)\n",
    "            xbound = [float(nx//2),float(ny//2),float(nz//2)]\n",
    "        \n",
    "        headf, tailf, numbf, used_mem, used_mem_tot = f.read_ints('i')\n",
    "        \n",
    "        ordering = f.read_ints(\"i\")\n",
    "        bound_key = f.read_ints(\"f8\")\n",
    "        info.bound_key = np.empty(info.ncpu+1)\n",
    "        if(len(bound_key) != info.ncpu+1):\n",
    "            print(\"Quad Hilbert not supported in python.\")\n",
    "            info.quadhilbert = True\n",
    "        else:\n",
    "            info.quadhilbert = False\n",
    "            info.bound_key[:] = bound_key\n",
    "        \n",
    "    filename = \"output_{dump:05d}/info_{dump:05d}.txt\".format(dump=dump)\n",
    "    data = ascii.read(filename, header_start=0, data_start=0, data_end=18, delimiter='=', names=[\"field\", \"value\"])\n",
    "    name = np.array(data[\"field\"])\n",
    "    val = np.array(data[\"value\"])\n",
    "    \n",
    "    info.ordering, = val[np.where(name==\"ordering type\")]\n",
    "    info.unit_l, = val[np.where(name==\"unit_l\")]\n",
    "    info.unit_d, = val[np.where(name==\"unit_d\")]\n",
    "    info.unit_t, = val[np.where(name==\"unit_t\")]\n",
    "    \n",
    "    return info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5731bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hilbert3d(x, y, z, bitlen):\n",
    "    \n",
    "    state_diagram = [ 1, 2, 3, 2, 4, 5, 3, 5,\n",
    "                      0, 1, 3, 2, 7, 6, 4, 5,\n",
    "                      2, 6, 0, 7, 8, 8, 0, 7,\n",
    "                      0, 7, 1, 6, 3, 4, 2, 5,\n",
    "                      0, 9, 10, 9, 1, 1, 11, 11,\n",
    "                      0, 3, 7, 4, 1, 2, 6, 5,\n",
    "                      6, 0, 6, 11, 9, 0, 9, 8,\n",
    "                      2, 3, 1, 0, 5, 4, 6, 7,\n",
    "                      11,11, 0, 7, 5, 9, 0, 7,\n",
    "                      4, 3, 5, 2, 7, 0, 6, 1,\n",
    "                      4, 4, 8, 8, 0, 6,10, 6,\n",
    "                      6, 5, 1, 2, 7, 4, 0, 3,\n",
    "                      5, 7, 5, 3, 1, 1,11,11,\n",
    "                      4, 7, 3, 0, 5, 6, 2, 1,\n",
    "                      6, 1, 6, 10, 9, 4, 9, 10,\n",
    "                      6, 7, 5, 4, 1, 0, 2, 3,\n",
    "                      10, 3, 1, 1, 10, 3, 5, 9,\n",
    "                      2, 5, 3, 4, 1, 6, 0, 7,\n",
    "                      4, 4, 8, 8, 2, 7, 2, 3,\n",
    "                      2, 1, 5, 6, 3, 0, 4, 7,\n",
    "                      7, 2,11, 2, 7, 5, 8, 5,\n",
    "                      4, 5, 7, 6, 3, 2, 0, 1,\n",
    "                      10, 3, 2, 6, 10, 3, 4, 4,\n",
    "                      6, 1, 7, 0, 5, 2, 4, 3]\n",
    "\n",
    "    state_diagram = np.array(state_diagram)\n",
    "    state_diagram = state_diagram.reshape((8, 2, 12), order='F')\n",
    "    order = np.zeros_like(x)\n",
    "    bit_mask = np.zeros(3*bitlen, dtype=bool)\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        \n",
    "        j = np.arange(bitlen)\n",
    "        bit_mask[2::3] = x[i] & (1 << np.arange(bitlen))\n",
    "        bit_mask[1::3] = y[i] & (1 << np.arange(bitlen))\n",
    "        bit_mask[0::3] = z[i] & (1 << np.arange(bitlen))\n",
    "\n",
    "        state = 0\n",
    "        for j in range(bitlen-1, -1, -1):\n",
    "            sdigit = np.sum(bit_mask[3*j:3*(j+1)] * 2**np.arange(3))\n",
    "            bit_mask[3*j:3*(j+1)] = state_diagram[sdigit, 1, state] & (1 << np.arange(3))\n",
    "            state = state_diagram[sdigit, 0, state]\n",
    "            \n",
    "        order[i] = np.sum(bit_mask * 2**np.arange(3*bitlen))\n",
    "\n",
    "    return order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "256d22d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'types.SimpleNamespace' object has no attribute 'bound_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx_cpu \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, info\u001b[38;5;241m.\u001b[39mncpu):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idom \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, ndom):\n\u001b[0;32m---> 35\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m( (\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound_key\u001b[49m[icpu] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m bounding_min[idom]) \u001b[38;5;129;01mand\u001b[39;00m (info\u001b[38;5;241m.\u001b[39mbound_key[icpu\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m bounding_min[idom]) ):\n\u001b[1;32m     36\u001b[0m             cpu_min[idom] \u001b[38;5;241m=\u001b[39m icpu\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m( (info\u001b[38;5;241m.\u001b[39mbound_key[icpu] \u001b[38;5;241m<\u001b[39m bounding_max[idom]) \u001b[38;5;129;01mand\u001b[39;00m (info\u001b[38;5;241m.\u001b[39mbound_key[icpu\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m bounding_max[idom]) ):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'types.SimpleNamespace' object has no attribute 'bound_key'"
     ]
    }
   ],
   "source": [
    "radius = 10*const.kpc\n",
    "center = np.array([0, 0, 0])\n",
    "\n",
    "ndim = 3\n",
    "boxlen = info.aexp*100*const.Mpc/const.h0\n",
    "radius_code = radius/info.length_unit\n",
    "center_code = center/info.length_unit + np.array([0.5, 0.5, 0.5])\n",
    "\n",
    "level_min = np.max([1, math.floor(np.log2(1/radius_code/2))])\n",
    "level_max = info.amr_level_sim_max\n",
    "bitlen = level_min-1\n",
    "\n",
    "dkey = 2**(ndim*(level_max-level_min))\n",
    "ibound = [0, 0, 0, 0, 0, 0]\n",
    "\n",
    "if (bitlen > 0):\n",
    "    ibound[0:3] = np.array((center_code-radius_code)*2**bitlen, dtype=int)\n",
    "    ibound[3:6] = np.array((center_code+radius_code)*2**bitlen, dtype=int)\n",
    "    ndom = 8\n",
    "    idom = [ibound[0], ibound[3]]*4\n",
    "    jdom = ([ibound[1]]*2 + [ibound[4]]*2)*2\n",
    "    kdom = [ibound[2]]*4 + [ibound[5]]*4\n",
    "    order_min = hilbert3d(idom, jdom, kdom, bitlen)\n",
    "else:\n",
    "    ndom = 1\n",
    "    order_min = np.array([0.])\n",
    "    \n",
    "bounding_min = order_min*dkey\n",
    "bounding_max = (order_min+1)*dkey\n",
    "\n",
    "cpu_min = np.zeros(ndom, dtype=int)\n",
    "cpu_max = np.zeros(ndom, dtype=int)\n",
    "for idx_cpu in range(0, info.ncpu):\n",
    "    for idom in range(0, ndom):\n",
    "        if( (info.bound_key[icpu] <= bounding_min[idom]) and (info.bound_key[icpu+1] > bounding_min[idom]) ):\n",
    "            cpu_min[idom] = icpu+1\n",
    "        if( (info.bound_key[icpu] < bounding_max[idom]) and (info.bound_key[icpu+1] >= bounding_max[idom]) ):\n",
    "            cpu_max[idom] = icpu+1\n",
    "\n",
    "\n",
    "ncpu_read = 0\n",
    "cpu_read = np.zeros(ncpu, dtype=bool)\n",
    "cpu_list = []\n",
    "for idom in range(0,ndom):\n",
    "    for icpu in range(cpu_min[idom]-1,cpu_max[idom]):\n",
    "        if ( not cpu_read[icpu] ):\n",
    "            cpu_list.append(icpu+1)\n",
    "            ncpu_read = ncpu_read+1\n",
    "            cpu_read[icpu] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "bc10d45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cpu_list(center, radius):\n",
    "    \n",
    "    for i in range(0, info.nlevelmax):\n",
    "        dx = 1/2**ilevel\n",
    "        if (dx < 2*radius/info.boxlen):\n",
    "            break\n",
    "\n",
    "    levelmin = np.max([ilevel,1])\n",
    "    bit_length = levelmin-1\n",
    "    nmax = 2**bit_length\n",
    "    ndim = info.ndim\n",
    "    ncpu = info.ncpu\n",
    "    nlevelmax = info.nlevelmax\n",
    "    dkey = 2**(ndim*(nlevelmax+1-bit_length))\n",
    "    ibound = [0, 0, 0, 0, 0, 0]\n",
    "    if(bit_length > 0):\n",
    "        ibound[0:3] = (center-radius)*nmax/info.boxlen\n",
    "        ibound[3:6] = (center+radius)*nmax/info.boxlen\n",
    "        ibound[0:3] = np.array(ibound[0:3]).astype(int)\n",
    "        ibound[3:6] = np.array(ibound[3:6]).astype(int)\n",
    "        ndom = 8\n",
    "        idom = [ibound[0], ibound[3], ibound[0], ibound[3], ibound[0], ibound[3], ibound[0], ibound[3]]\n",
    "        jdom = [ibound[1], ibound[1], ibound[4], ibound[4], ibound[1], ibound[1], ibound[4], ibound[4]]\n",
    "        kdom = [ibound[2], ibound[2], ibound[2], ibound[2], ibound[5], ibound[5], ibound[5], ibound[5]]\n",
    "        order_min = hilbert3d(idom,jdom,kdom,bit_length)\n",
    "    else:\n",
    "        ndom = 1\n",
    "        order_min = np.array([0.])\n",
    "        \n",
    "    bounding_min = order_min*dkey\n",
    "    bounding_max = (order_min+1)*dkey\n",
    "\n",
    "    cpu_min = np.zeros(ndom, dtype=int)\n",
    "    cpu_max = np.zeros(ndom, dtype=int)\n",
    "    for icpu in range(0,ncpu):\n",
    "        for idom in range(0,ndom):\n",
    "            if( (info.bound_key[icpu] <= bounding_min[idom]) and (info.bound_key[icpu+1] > bounding_min[idom]) ):\n",
    "                cpu_min[idom] = icpu+1\n",
    "            if( (info.bound_key[icpu] < bounding_max[idom]) and (info.bound_key[icpu+1] >= bounding_max[idom]) ):\n",
    "                cpu_max[idom] = icpu+1\n",
    "\n",
    "\n",
    "    ncpu_read = 0\n",
    "    cpu_read = np.zeros(ncpu, dtype=bool)\n",
    "    cpu_list = []\n",
    "    for idom in range(0,ndom):\n",
    "        for icpu in range(cpu_min[idom]-1,cpu_max[idom]):\n",
    "            if ( not cpu_read[icpu] ):\n",
    "                cpu_list.append(icpu+1)\n",
    "                ncpu_read = ncpu_read+1\n",
    "                cpu_read[icpu] = True\n",
    "\n",
    "    return cpu_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7660d29b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'types.SimpleNamespace' object has no attribute 'nlevelmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_cpu_list\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[58], line 3\u001b[0m, in \u001b[0;36mget_cpu_list\u001b[0;34m(center, radius)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_cpu_list\u001b[39m(center, radius):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlevelmax\u001b[49m):\n\u001b[1;32m      4\u001b[0m         dx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39milevel\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (dx \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mradius\u001b[38;5;241m/\u001b[39minfo\u001b[38;5;241m.\u001b[39mboxlen):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'types.SimpleNamespace' object has no attribute 'nlevelmax'"
     ]
    }
   ],
   "source": [
    "get_cpu_list(0, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ecff850",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_star = np.array([])\n",
    "    tau_starbirth = np.array([])\n",
    "    for i in range(1, info.ncpu+1):\n",
    "        partfile = os.path.join(\"output_%.5d\" % dump, \"part_%.5d.out%.5d\" % (dump, i))\n",
    "        with FortranFile(partfile, 'r') as f:\n",
    "            _, _, _ = f.read_ints('i'), f.read_ints('i'), f.read_ints('i')\n",
    "            _, _, _, _, _ = f.read_reals('f8'), f.read_reals('f4'), f.read_reals('f8'), f.read_reals('f8'), f.read_reals('f4')\n",
    "            _, _, _ = f.read_reals('f8'), f.read_reals('f8'), f.read_reals('f8') # position\n",
    "            _, _, _ = f.read_reals('f8'), f.read_reals('f8'), f.read_reals('f8') # velocity\n",
    "            _ = f.read_reals('f8') # mass\n",
    "            id_part = f.read_ints('i') # id\n",
    "            _ = f.read_ints('i') # level\n",
    "            type_part = f.read_ints('b') # family\n",
    "            _ = f.read_ints('b') # tag\n",
    "            tau_partbirth = f.read_reals('f8') # birthtime\n",
    "            _ = f.read_reals('f8') # metallicity\n",
    "            id_star = np.concatenate((id_star, id_part[type_part==STAR]))\n",
    "            tau_starbirth = np.concatenate((tau_starbirth, tau_partbirth[type_part==STAR]))\n",
    "    integrand = lambda a: (info.Omega_m0 * a**(-1) + info.Omega_k0 + info.Omega_L0 * a**2)**(-1/2)\n",
    "    age_universe = quad(integrand, 0, 1)[0] / info.H0\n",
    "    time_starbirth = tau_starbirth / info.H0 + age_universe\n",
    "    return id_star, time_starbirth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7135149e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'quad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mread_partfile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m54\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 32\u001b[0m, in \u001b[0;36mread_partfile\u001b[0;34m(dump)\u001b[0m\n\u001b[1;32m     30\u001b[0m         tau_starbirth \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((tau_starbirth, tau_partbirth[type_part\u001b[38;5;241m==\u001b[39mSTAR]))\n\u001b[1;32m     31\u001b[0m integrand \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m a: (info\u001b[38;5;241m.\u001b[39mOmega_m0 \u001b[38;5;241m*\u001b[39m a\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m info\u001b[38;5;241m.\u001b[39mOmega_k0 \u001b[38;5;241m+\u001b[39m info\u001b[38;5;241m.\u001b[39mOmega_L0 \u001b[38;5;241m*\u001b[39m a\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m age_universe \u001b[38;5;241m=\u001b[39m \u001b[43mquad\u001b[49m(integrand, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m info\u001b[38;5;241m.\u001b[39mH0\n\u001b[1;32m     33\u001b[0m time_starbirth \u001b[38;5;241m=\u001b[39m tau_starbirth \u001b[38;5;241m/\u001b[39m info\u001b[38;5;241m.\u001b[39mH0 \u001b[38;5;241m+\u001b[39m age_universe\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m id_star, time_starbirth\n",
      "\u001b[0;31mNameError\u001b[0m: name 'quad' is not defined"
     ]
    }
   ],
   "source": [
    "read_partfile(54)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe27af2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
